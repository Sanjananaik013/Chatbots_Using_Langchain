ğŸ“Œ **Project Description**

This project demonstrates how to build and expose LLM-powered APIs using LangChain + FastAPI (LangServe) and consume them through a Streamlit UI.

app.py â†’ Backend FastAPI server that exposes LLM pipelines (Gemini & Llama2) as APIs using LangServe.

client.py â†’ Frontend Streamlit app that sends user input to the APIs and displays the generated responses.

It integrates:

  â€¢ Google Gemini (for Essay generation)

  â€¢ Ollama Llama2 (for Poem generation)

âš™ï¸ **Tech Stack**

  LangChain, LangServe, FastAPI, Streamlit, Google Gemini API, Ollama (Llama2)

ğŸš€ **Features**

â€¢ Exposes LLM pipelines as REST APIs

â€¢ Essay generation using Gemini

â€¢ Poem generation using Llama2

â€¢ Streamlit frontend for interaction

â€¢ Demonstrates prompt â†’ model â†’ API â†’ UI workflow

